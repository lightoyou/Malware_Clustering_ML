#-*- coding: utf-8 -*-
import lief
from lief import to_json
import hashlib
import json
from collections import Counter
import os




def get_hashes(data,isFile):
    if isFile == True:
        afile = open(data, 'rb')
        buf = afile.read()
    elif isFile == False:
        buf = data

    md5_hash = hashlib.md5()
    sha1_hash = hashlib.sha1()
    sha256_hash = hashlib.sha256()
    #ssdeep_hash = ssdeep.Hash()

    md5_hash.update(buf)
    sha1_hash.update(buf)
    sha256_hash.update(buf)
    #ssdeep_hash.update(bytes(data))
    #return #ssdeep_hash.digest()
    return md5_hash.hexdigest(), sha1_hash.hexdigest(), sha256_hash.hexdigest()



def dump_sections(pe):
    sections = []

    for section in pe.sections:
        sectionDict = {
        'name': section.name,
        'characteristics': section.characteristics,
        'virtual_size': hex(section.virtual_size),
        'size': hex(section.size),
        'virtual_address': hex(section.virtual_address),
        'entropy': section.entropy
        }
        sections.append(sectionDict)
    return sections
        #TODOO CALC HASH OF SECTIONS
        #section.content
        #md5_sec, sha1_sec, sha256_sec = get_hashes(section.content, False)

def load(file):
    pe = lief.parse(file)
    dictPE = {
                "type" : "PE",
                "hashes": {},
                "path" : file,
                "name" : pe.name,
                "sections": [],
                "entrypoint" : hex(pe.entrypoint),
                "nb_sections" : len(pe.sections),
                "imported_fonction": pe.imported_functions,
                "imported_libraries": pe.libraries,

            }
    dictPE['hashes']['md5'], dictPE['hashes']['sha1'], dictPE['hashes']['sha256'] = get_hashes(file,True)
    sections = dump_sections(pe)
    dictPE['sections'].append(sections)
    #print(pe.exported_functions)
    return dictPE

AllFiles = []
PathDataset = "/home/light/Documents/Cours_CDSI/ML/dataset/theZoo/malwares/Binaries"
#PathDataset = "dataset/"
for root, subFolders, files in os.walk(PathDataset):
    for file in files:
        PathDataset = os.path.join(root, file)
        rootPath = os.path.join(root)
        AllFiles.append(PathDataset)


AllPE = []
for p in AllFiles:
    try:
        file_json = load(p)
        #print(file_json)
        AllPE.append(file_json)
    except:
        pass

for p in AllPE:
    json.dump( p ,open('%s.json' %os.path.join('jsonfiles', p['hashes']['sha256']),'w'))

#Check collisions
AllSha256 = [ p['hashes']['sha256']for p in AllPE]
c = Counter()
for s in AllSha256:
    c[s] +=1
collision = [ k for k,v in c.items() if v > 1]
[(p['hashes']['sha256'] ,p['path']) for p in AllPE if p['hashes']['sha256'] in collision]
